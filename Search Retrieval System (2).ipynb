{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Retrieval System\n",
    "## CSC 575 Final Project\n",
    "### Ayesha Ali, Swathi Babu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NE0Rvjuec5s6",
    "outputId": "61969a85-db03-4453-b6c2-9e81f7b82d1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a0ptm0ZlzVTD"
   },
   "outputs": [],
   "source": [
    "inverted_index1={}\n",
    "docLengths1={}\n",
    "def crawl_directory(filepath):\n",
    "    Ndoc=0\n",
    "    for directory, subdirlist, filelist in os.walk(filepath):\n",
    "        dirList = []\n",
    "        for f in filelist:\n",
    "            #print('\\t' + f)\n",
    "            #print('sub',subdirlist)\n",
    "            if f=='.DS_Store':\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    \n",
    "                    docid = f\n",
    "\n",
    "                    doc = preprocess_words(open(directory+'/'+f).read())\n",
    "                    #print('print doc',directory+'/'+f)\n",
    "                    Ndoc+=1\n",
    "\n",
    "\n",
    "                    create_inverted_index(doc, docid,inverted_index1)\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "    doc_lengths(inverted_index1, docLengths1, Ndoc)\n",
    "    with open('inverted_index1.json', 'w') as f:\n",
    "        json.dump(inverted_index1, f)\n",
    "    with open('doc_lengths1.json', 'w') as f:\n",
    "        json.dump(docLengths1, f)\n",
    "    print(len(inverted_index1))\n",
    "    return Ndoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zqIeEP9YqEwB"
   },
   "outputs": [],
   "source": [
    "def preprocess_words(line):\n",
    "    '''Function to preprocess the tokens'''\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation)) #Removing Punctuation\n",
    "    line = line.lower().strip() #making it lower case and removing additional spaces\n",
    "    stopWords = set(stopwords.words('english')) #stopwords\n",
    "    tokens = word_tokenize(line) #creating a list of words\n",
    "    words = [x for x in tokens if not x in stopWords] #removing stopwords\n",
    "    #Stemming\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = ps.stem(words[i])\n",
    "    #returning the list of words/tokens\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Oc9GnPM9dEbm"
   },
   "outputs": [],
   "source": [
    "def tf_idf(dict, N):\n",
    "    ''' to find the idf values of the given term'''\n",
    "    idf = np.log2(N / len(dict))  \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mJ2xA0hyvKju"
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(doc, docid, inverted_index):\n",
    "    ''' to create the inverted index for given set of documents'''\n",
    "    for token in doc:\n",
    "        #if token not in dict, add the token\n",
    "        if token not in inverted_index:\n",
    "            inverted_index[token] = {}\n",
    "        #for each token, a nested dict containing doc id and count in that doc\n",
    "        if docid not in inverted_index[token]:\n",
    "            inverted_index[token][docid] = 0\n",
    "        #incrementing count by 1 for that doc id\n",
    "        inverted_index[token][docid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MIxbhFrhdJV7"
   },
   "outputs": [],
   "source": [
    "def doc_lengths(inverted_index, docLengths, NDoc):\n",
    "    ''' to create dictionary storing the document lengths for the given set of documents'''\n",
    "    #Incrementing the Document lengths\n",
    "    for i in inverted_index:\n",
    "        idf = tf_idf(inverted_index[i], NDoc)\n",
    "        for j in inverted_index[i]:\n",
    "            if j in docLengths.keys():\n",
    "                docLengths[j] += ((inverted_index[i][j] * idf)**2)\n",
    "            else:\n",
    "                docLengths[j] = ((inverted_index[i][j] * idf)**2)\n",
    "        for w in docLengths:\n",
    "            docLengths[w] = np.sqrt(docLengths[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "N0T10hTsysWO"
   },
   "outputs": [],
   "source": [
    "def readfile(filepath, linestart, inverted_index, docLengths):\n",
    "    '''Reads through the set of documents and calls the function that creates inverted index and doc length dictionaries'''\n",
    "    with open(filepath) as file:\n",
    "        line = file.readline()\n",
    "        docid = None\n",
    "        doc = [] #tokens of document #\n",
    "        NDoc = 0 #number of documents\n",
    "        while line:\n",
    "            if line.startswith(linestart):\n",
    "                NDoc+=1\n",
    "                create_inverted_index(doc, docid, inverted_index) #sending the previous document tokens and the id to update the inverted index\n",
    "                doc = [] #reloading the doc list to store tokens for the next document\n",
    "                try:\n",
    "                    docid = int(line.strip().replace(linestart, '' )) #processing on document id to get user friendly form\n",
    "                except ValueError:\n",
    "                    docid = line.strip().replace(linestart, '' )\n",
    "                line = file.readline() \n",
    "            else:\n",
    "                doc +=(preprocess_words(line))\n",
    "            line = file.readline()\n",
    "    create_inverted_index(doc, docid, inverted_index)\n",
    "    doc_lengths(inverted_index, docLengths, NDoc)\n",
    "    return(NDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KV52JLwXXBA-"
   },
   "outputs": [],
   "source": [
    "def query_process(query): \n",
    "    '''Pre-processes the query and creates the query vector in dictionary form'''\n",
    "    p_query = preprocess_words(query)\n",
    "    #CALCULATING THE QUERY DICTIONARY \n",
    "    QtermDict = {}\n",
    "    for k in p_query:\n",
    "        if k in QtermDict.keys():\n",
    "            QtermDict[k]+=1\n",
    "        else:\n",
    "            QtermDict[k] = 1\n",
    "    return p_query, QtermDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9AKFaOEGeKQ3"
   },
   "outputs": [],
   "source": [
    "#CALCULATING THE DOT PRODUCT SCORES FOR ONE QUERY\n",
    "def retrieval_scores(p_query, QtermDict, NDoc, inverted_index):\n",
    "    '''Calculates the retrieval scores for the documents for a given query'''\n",
    "    rankDict = {} #Scores for the documents\n",
    "    Qlength = 0 #Calculating query lengths\n",
    "    for i in set(p_query): #going through the query terms\n",
    "        try:\n",
    "            idf = tf_idf(inverted_index[i], NDoc) #Calculating idf of the term\n",
    "            Qlength+= (idf**2) #incrementing the query length\n",
    "            for j in (inverted_index[i]): #going through each document in the postings and incrementing the respective dictionaries\n",
    "            #Incrementing the document scores\n",
    "                if j in rankDict.keys():\n",
    "                    rankDict[j] += (inverted_index[i][j] * idf)*(QtermDict[i] * idf)\n",
    "                else:\n",
    "                    rankDict[j] = (inverted_index[i][j] * idf)*(QtermDict[i] * idf)\n",
    "        except:\n",
    "              continue\n",
    "    #Applying square root for Query length\n",
    "    Qlength = np.sqrt(Qlength)\n",
    "    return (Qlength, rankDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4HKXEXUXechm"
   },
   "outputs": [],
   "source": [
    "#RANKING BASED ON COSINE FOR THE GIVEN QUERY\n",
    "def cosine_Ranking(rankDict, Qlength,docLengths):\n",
    "    '''Calculates the cosine ranking and sorts based on it for a given query'''\n",
    "    cosineRank = {}\n",
    "    for r in rankDict:\n",
    "        cosineRank[r] = rankDict[r]/(Qlength*docLengths[r])\n",
    "    #Sorting the dictionary based on ranking\n",
    "    cosineRank_sorted = dict(sorted(cosineRank.items(), key = lambda item: item[1], reverse = True))\n",
    "    return cosineRank_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AYwJ6yIq3t7T"
   },
   "outputs": [],
   "source": [
    "def modify_query_rocchio(Q, R, NR, alpha, beta):\n",
    "    '''Runs standard IR Rocchio relevance feedback method'''\n",
    "    mean_R = np.mean(R, axis=0)\n",
    "    mean_NR = np.mean(NR, axis=0)\n",
    "    #rochio formula\n",
    "    Q1= Q+(alpha*mean_R)-(beta*mean_NR)\n",
    "    Q1 = np.maximum(Q1, 0) #converting negative entries to 0\n",
    "    return Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ELQJf97y30Ys"
   },
   "outputs": [],
   "source": [
    "def rocchio_process(rankedDocs, rel, QtermDict,k,inverted_index):\n",
    "    '''Creates the TD matrix with just the top 10 retrieved documents to use for rocchio method and creates a query vector after rocchio'''\n",
    "    retDocs = list(rankedDocs.keys())[:k] #Top 10 retrieved documents\n",
    "    #creating a dataframe to create vectors of the relevant and non-relevant docs\n",
    "    DT = pd.DataFrame(index = retDocs) \n",
    "    for i in inverted_index:\n",
    "        for j in inverted_index[i]:\n",
    "            if j in retDocs:\n",
    "                DT.loc[j,i] = inverted_index[i][j]\n",
    "    DT.fillna(0, inplace = True)\n",
    "    terms = DT.columns #terms in these docs\n",
    "    Qdict = QtermDict.copy() #creating the new query doc (used for retrieval)\n",
    "    #If the terms in query don't exist in the documents\n",
    "    for j in Qdict:\n",
    "        if j not in terms:\n",
    "            DT.loc[:,j] = 0\n",
    "    #creating the new query doc (used for retrieval)\n",
    "    for x in terms:\n",
    "        if x not in Qdict.keys():\n",
    "            Qdict[x] = 0\n",
    "    #Query vector\n",
    "    Q = np.array(list(Qdict.values()))\n",
    "    #Relevant documents matrix\n",
    "    #relRet = set(retDocs) & set(rel)#relevant documents retrieved\n",
    "    relRet = list(set(list(DT.index)) & set(rel))\n",
    "    R = np.array([DT.loc[i,:] for i in relRet])\n",
    "    #Non-Relevant documents matrix\n",
    "    notrel = list(set(list(DT.index)) - set(rel))\n",
    "    NR = np.array([DT.loc[i,:] for i in notrel])\n",
    "    #Calling the Rocchio function\n",
    "    alpha = 0.5\n",
    "    beta = 0.25\n",
    "    Q1 = modify_query_rocchio(Q, R, NR, alpha, beta)\n",
    "    #Creating a new query dictionary with the Rocchio results\n",
    "    for i in range(len(terms)):\n",
    "        Qdict[terms[i]] = Q1[i]\n",
    "    return (terms,Qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K2IQeUkA33cz"
   },
   "outputs": [],
   "source": [
    "def feedback_user(QtermDict, relevant,k,rankedDocs,inverted_index,docLengths,NDoc):\n",
    "    '''Runs the rocchio process and then using the new query vector, finds the new retrieved documents'''\n",
    "    #Running the rocchio process\n",
    "    terms, Qdict =rocchio_process(rankedDocs, relevant, QtermDict, k,inverted_index)\n",
    "    #getting the new query vector and getting scores for the new query\n",
    "    Qlength1, rankDict1 = retrieval_scores(terms,Qdict, NDoc, inverted_index)\n",
    "    newrankedDocs = cosine_Ranking(rankDict1, Qlength1,docLengths)\n",
    "    return (newrankedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P-r6bV8dH73c"
   },
   "outputs": [],
   "source": [
    "def print_title(i_num): #Function to print the title of the given doc id --> specific to MED files\n",
    "    '''Function to print the title of MED documents'''\n",
    "    text = \"\"\n",
    "    with open('/Users/admin/Desktop/courses2/IR_Project/med/MED.ALL', \"r\") as f:\n",
    "        line = f.readline().strip()\n",
    "        while line:\n",
    "            if line.startswith(\".I\"):\n",
    "                current_i_num = line.split()[1]\n",
    "                if current_i_num == i_num:\n",
    "                  # Found the desired I number, skip lines until \".W\"\n",
    "                    line = f.readline().strip()\n",
    "                    while not line.startswith(\".W\"):\n",
    "                        line = f.readline().strip()\n",
    "\n",
    "                  # Read lines until first full stop \n",
    "                  #1st line\n",
    "                    line = f.readline().strip()\n",
    "                    if line.endswith('.'):\n",
    "                        text=line\n",
    "                        break    \n",
    "                  #if the title is more than one line\n",
    "                    text=''\n",
    "                    while line and not line.startswith(\".\"):\n",
    "                        text += line + \" \"\n",
    "                        line = f.readline().strip()\n",
    "                        if \".\" in line:\n",
    "                            text += line[:line.index(\".\")] + \" \"\n",
    "                            break\n",
    "                  # Finished reading text for desired I number, exit loop\n",
    "                    break\n",
    "            line = f.readline().strip()\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n9OIMGF33_t2"
   },
   "outputs": [],
   "source": [
    "def printDocs(rankedDocs):\n",
    "    '''Function to print the top 10 documents'''\n",
    "    n = 10 #Number of documents to retrieve\n",
    "    for i in rankedDocs:\n",
    "        if n>0:\n",
    "            print('\\nDocument', i)\n",
    "            print_title(i)\n",
    "            print('\\n')\n",
    "            n-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7YvUb4Xz5Q36"
   },
   "outputs": [],
   "source": [
    "def first_time(filepath = '/Users/admin/Desktop/courses2/IR_Project/med/MED.ALL'):\n",
    "    '''Function to run for the first time'''\n",
    "    inverted_index = {}\n",
    "    doc_lengths = {}\n",
    "    NDoc = readfile(filepath, '.I', inverted_index, doc_lengths)\n",
    "    # Save dictionary to file using JSON\n",
    "    with open('inverted_index.json', 'w') as f:\n",
    "        json.dump(inverted_index, f)\n",
    "    with open('doc_lengths.json', 'w') as f:\n",
    "        json.dump(doc_lengths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mDrjhD0h18P9"
   },
   "outputs": [],
   "source": [
    "def precision_recall(ret, rel):\n",
    "    '''Calculates the precision and recall'''\n",
    "    #ret = [int(a) for a in ret]\n",
    "    com = set(ret) & set(rel)\n",
    "    recall = len(com)/len(rel)\n",
    "    precision = len(com)/ len(ret)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cv7u8hcWuKGE"
   },
   "outputs": [],
   "source": [
    "def query_eval_10():\n",
    "    '''Presicion and Recall for the 30 test queries'''\n",
    "    pres = []\n",
    "    rec = []\n",
    "    pres_roc = []\n",
    "    rec_roc = []\n",
    "    D = pd.read_csv('/Users/admin/Desktop/courses2/IR_Project/med/MED.REL', header = None, sep = ' ', index_col = 0)\n",
    "    with open('inverted_index.json', 'r') as f:\n",
    "        inverted_index = json.load(f)\n",
    "    with open('doc_lengths.json', 'r') as f:\n",
    "        docLengths = json.load(f)\n",
    "    NDoc = len(docLengths)\n",
    "    f = open('/Users/admin/Desktop/courses2/IR_Project/med/MED.QRY')\n",
    "    line = f.readline()\n",
    "    docid = int(line[3:].strip())\n",
    "    line = f.readline()\n",
    "    line = f.readline()\n",
    "    query=''\n",
    "    while line:\n",
    "        if line.startswith('.I'):\n",
    "            #The previous query is completely read so running the system for that query\n",
    "            print(docid)\n",
    "            print(query)\n",
    "            p_query, QtermDict = query_process(query)\n",
    "            Qlength, rankDict = retrieval_scores(p_query, QtermDict, NDoc,inverted_index)\n",
    "            rankedDocs = cosine_Ranking(rankDict, Qlength,docLengths)\n",
    "            ret = list(rankedDocs.keys())[0:10]\n",
    "            rel = list(D.loc[docid,2])\n",
    "            rel = [str(x) for x in rel]\n",
    "            i,j = precision_recall(ret,rel)\n",
    "            pres.append(i)\n",
    "            rec.append(j)\n",
    "          #After Rocchio \n",
    "            newrankedDocs = feedback_user(QtermDict, rel, 10,rankedDocs,inverted_index,docLengths,NDoc)\n",
    "            ret_new = list(newrankedDocs.keys())[0:10]\n",
    "            i1,j1 = precision_recall(ret_new,rel)\n",
    "            pres_roc.append(i1)\n",
    "            rec_roc.append(j1)\n",
    "            #Initializing for the next query\n",
    "            docid = int(line[3:].strip())\n",
    "            query = ''\n",
    "            line = f.readline()\n",
    "        else:\n",
    "            query = query + line\n",
    "        line = f.readline()\n",
    "    print(docid)\n",
    "    print(query)\n",
    "    p_query, QtermDict = query_process(query)\n",
    "    Qlength, rankDict = retrieval_scores(p_query, QtermDict, NDoc, inverted_index)\n",
    "    rankedDocs = cosine_Ranking(rankDict, Qlength,docLengths)\n",
    "    ret = list(rankedDocs.keys())[0:10]\n",
    "    rel = list(D.loc[docid,2])\n",
    "    i,j = precision_recall(ret,rel)\n",
    "    pres.append(i)\n",
    "    rec.append(j)\n",
    "    newrankedDocs = feedback_user(QtermDict, rel,10,rankedDocs,inverted_index,docLengths,NDoc)\n",
    "    ret_new = list(newrankedDocs.keys())[0:10]\n",
    "    i1,j1 = precision_recall(ret_new,rel)\n",
    "    pres_roc.append(i1)\n",
    "    rec_roc.append(j1)\n",
    "    print('Before Rocchio:')\n",
    "    print('The Precision value:', sum(pres)/len(pres))\n",
    "    print('The Recall value:',sum(rec)/len(rec))\n",
    "    print('\\nAfter Rocchio:')\n",
    "    print('The Precision value:', sum(pres_roc)/len(pres_roc))\n",
    "    print('The Recall value:', sum(rec_roc)/len(rec_roc))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okXo3tpM6jaZ",
    "outputId": "f03b753e-78ee-4d6b-eef4-d6d2d5fba364"
   },
   "outputs": [],
   "source": [
    "def precision_Recall_plot():\n",
    "    '''Plot for finding ideal number of retrieved documents'''\n",
    "    with open('inverted_index.json', 'r') as f:\n",
    "        inverted_index = json.load(f)\n",
    "    with open('doc_lengths.json', 'r') as f:\n",
    "        docLengths = json.load(f)\n",
    "    NDoc = len(docLengths)\n",
    "    pres_k = []\n",
    "    rec_k =[]\n",
    "    pres_k_roc =[]\n",
    "    rec_k_roc = []\n",
    "    for k in range(5,16): #k is the number of retrieved documents\n",
    "        pres = []\n",
    "        rec = []\n",
    "        pres_roc = []\n",
    "        rec_roc = []\n",
    "        f = open('/Users/admin/Desktop/courses2/IR_Project/med/MED.QRY')\n",
    "        D = pd.read_csv('/Users/admin/Desktop/courses2/IR_Project/med/MED.REL', header = None, sep = ' ', index_col = 0)\n",
    "        line = f.readline()\n",
    "        docid = int(line[3:].strip())\n",
    "        line = f.readline()\n",
    "        line = f.readline()\n",
    "        query=''\n",
    "        while line:\n",
    "            if line.startswith('.I'):\n",
    "                #The previous query is completely read so running the system for that query\n",
    "                p_query, QtermDict = query_process(query)\n",
    "                Qlength, rankDict = retrieval_scores(p_query, QtermDict, NDoc,inverted_index)\n",
    "                rankedDocs = cosine_Ranking(rankDict, Qlength,docLengths)\n",
    "                ret = list(rankedDocs.keys())[0:k]\n",
    "                rel = list(D.loc[docid,2])\n",
    "                rel = [str(x) for x in rel]\n",
    "                i,j = precision_recall(ret,rel)\n",
    "                pres.append(i)\n",
    "                rec.append(j)\n",
    "                #After Rocchio \n",
    "                newrankedDocs = feedback_user(QtermDict, rel,k,rankedDocs,inverted_index,docLengths,NDoc)\n",
    "                ret_new = list(newrankedDocs.keys())[0:k]\n",
    "                i1,j1 = precision_recall(ret_new,rel)\n",
    "                pres_roc.append(i1)\n",
    "                rec_roc.append(j1)\n",
    "                #Initializing for the next query\n",
    "                docid = int(line[3:].strip())\n",
    "                query = ''\n",
    "                line = f.readline()\n",
    "            else:\n",
    "                query = query + line\n",
    "            line = f.readline()\n",
    "        p_query, QtermDict = query_process(query)\n",
    "        Qlength, rankDict = retrieval_scores(p_query, QtermDict, NDoc, inverted_index)\n",
    "        rankedDocs = cosine_Ranking(rankDict, Qlength,docLengths)\n",
    "        ret = list(rankedDocs.keys())[0:k]\n",
    "        rel = list(D.loc[docid,2])\n",
    "        i,j = precision_recall(ret,rel)\n",
    "        pres.append(i)\n",
    "        rec.append(j)\n",
    "        \n",
    "        newrankedDocs = feedback_user(QtermDict, rel,k,rankedDocs,inverted_index,docLengths,NDoc)\n",
    "        ret_new = list(newrankedDocs.keys())[0:k]\n",
    "        i1,j1 = precision_recall(ret_new,rel)\n",
    "        pres_roc.append(i1)\n",
    "        rec_roc.append(j1)\n",
    "        print(k)\n",
    "        pres_k.append(sum(pres)/len(pres))\n",
    "        rec_k.append(sum(rec)/len(rec))\n",
    "        pres_k_roc.append(sum(pres_roc)/len(pres_roc))\n",
    "        rec_k_roc.append( sum(rec_roc)/len(rec_roc))\n",
    "        #print(sum(pres)/len(pres), sum(rec)/len(rec))\n",
    "        #print(sum(pres_roc)/len(pres_roc), sum(rec_roc)/len(rec_roc))\n",
    "        f.close()\n",
    "        \n",
    "    #Before Rocchio pres rec plot\n",
    "    plt.plot(range(5, 16), pres_k, label='Precision')\n",
    "    plt.plot(range(5, 16), rec_k, label='Recall')\n",
    "    plt.xlabel('Number of Documents')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Precision vs Recall - BEFORE ROCCHIO')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #After Rocchio pres rec plot\n",
    "    plt.plot(range(5, 16), pres_k_roc, label='Precision')\n",
    "    plt.plot(range(5, 16), rec_k_roc, label='Recall')\n",
    "    plt.xlabel('Number of Documents')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Precision vs Recall - AFTER ROCCHIO')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return pres_k,rec_k,pres_k_roc, rec_k_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''Main function of the system'''\n",
    "    #LOAD INVERTED INDEX AND DOCUMENT LENGTHS\n",
    "    try:\n",
    "        with open('inverted_index.json', 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "        with open('doc_lengths.json', 'r') as f:\n",
    "            docLengths = json.load(f)\n",
    "    except:\n",
    "        first_time()\n",
    "        #crawl_directory('/Users/admin/Desktop/courses2/IR_Project/20_newsgroups')\n",
    "    NDoc = len(docLengths)\n",
    "    #INITIALIZE GUI WINDOW\n",
    "    window = tk.Tk()\n",
    "    window.title(\"CSC 575 Information Retrieval System\")\n",
    "    window.geometry(\"1000x1600\")\n",
    "\n",
    "    #ADD LABELS AND TEXT BOXES TO GUI WINDOW\n",
    "    query_label = tk.Label(window, text=\"Enter your Query:\")\n",
    "    query_label.pack()\n",
    "    query_entry = tk.Entry(window,width=60)\n",
    "    query_entry.pack()\n",
    "\n",
    "    output_label = tk.Label(window, text=\"Search Results:\")\n",
    "    output_label.pack()\n",
    "    output_text = scrolledtext.ScrolledText(window, height=20)\n",
    "    output_text.pack()\n",
    "\n",
    "    #HANDLE SEARCH BUTTON CLICK\n",
    "    def search():\n",
    "        query = query_entry.get()\n",
    "        p_query, QtermDict = query_process(query)\n",
    "        Qlength, rankDict = retrieval_scores(p_query, QtermDict, NDoc, inverted_index)\n",
    "        rankedDocs_2 = cosine_Ranking(rankDict, Qlength,docLengths)\n",
    "        #output_text.delete(\"1.0\", tk.END)\n",
    "        n=10\n",
    "        for i in rankedDocs_2:\n",
    "            if n>0:\n",
    "                output_text.insert(tk.END, f\"\\nDocument {i}\\n\")\n",
    "                output_text.insert(tk.END, print_title(i))\n",
    "                output_text.insert(tk.END, '\\n'+'-'*70)\n",
    "                n-=1\n",
    "        \n",
    "        feedback_label = tk.Label(window, text=\"Would you like to provide feedback on the relevance of the documents? (Y/N)\")\n",
    "        feedback_label.pack()\n",
    "        feedback_entry = tk.Entry(window)\n",
    "        feedback_entry.pack()\n",
    "        \n",
    "        \n",
    "\n",
    "        def feedback():\n",
    "            \n",
    "            def feedback1():\n",
    "               \n",
    "                relevant = literal_eval(relevant_entry.get())\n",
    "                relevant = [str(x) for x in relevant]\n",
    "                if relevant:\n",
    "                    newrankedDocs = feedback_user(QtermDict, relevant, 10,rankedDocs_2,inverted_index,docLengths,NDoc)\n",
    "                    #output_text.delete(\"1.0\", tk.END)\n",
    "                    n=10\n",
    "                    output_label1 = tk.Label(window, text=\"Search Results:\")\n",
    "                    output_label1.pack()\n",
    "                    output_text1 = scrolledtext.ScrolledText(window, height=20)\n",
    "                    output_text1.pack()\n",
    "\n",
    "                    for i in newrankedDocs:\n",
    "                        if n>0:\n",
    "                            output_text1.insert(tk.END, f\"\\nDocument {i}\\n\")\n",
    "                            output_text1.insert(tk.END, print_title(i))\n",
    "                            output_text1.insert(tk.END, '\\n'+'-'*70)\n",
    "                            n-=1\n",
    "            \n",
    "            if  feedback_entry.get()=='Y':\n",
    "                relevant_label = tk.Label(window, text=\"Please type out the IDs of the relevant documents from above [docid1, docid2,..]:\")\n",
    "                relevant_label.pack()\n",
    "                relevant_entry = tk.Entry(window,width=60)\n",
    "                relevant_entry.pack()\n",
    "                \n",
    "                feedback_button1 = tk.Button(window, text=\"Submit Relevant docs\", command=feedback1)\n",
    "                feedback_button1.pack()\n",
    "            \n",
    "        feedback_button = tk.Button(window, text=\"Submit Feedback\", command=feedback)\n",
    "        feedback_button.pack()\n",
    "    #TO CALL MAIN FUNCTION AND CONTINUE THE LOOP\n",
    "    def callMain():\n",
    "        window.destroy()\n",
    "        main()\n",
    "        \n",
    "    #ADD SEARCH BUTTON TO GUI WINDOW\n",
    "    search_button = tk.Button(window, text=\"Search\", command=search)\n",
    "    search_button.pack()\n",
    "\n",
    "    #ADD QUIT BUTTON TO GUI WINDOW\n",
    "    quit_button = tk.Button(window, text=\"Click for new Search\", command= callMain)\n",
    "    quit_button.pack()\n",
    "\n",
    "    #START GUI EVENT LOOP\n",
    "    window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
